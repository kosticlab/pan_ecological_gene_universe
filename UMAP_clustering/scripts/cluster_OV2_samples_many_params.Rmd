---
title: "cluster_OV2_samples_many_params"
author: "Sam Zimmerman"
date: "4/16/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
setwd("~/Dropbox (HMS)/Kostic_Lab/datasets/orfletonV2/complete_linkage_analysis/clustering")
```

#First make UMAPs and cluster using HDBSCAN

```{r}
library(umap)
library(cluster)
library(dbscan)
library(ggplot2)
library(data.table)
library(gridExtra)

### function to do hdbscan clustering, and get sihouette score
clac_silhouette_score = function(mymat,minclust) {
hdb_res = hdbscan(x=mymat$layout,minPts=minclust)
# calc silhouette score
# first get members that are in clusters
hdb_res_inclust = which(hdb_res$cluster!= 0)
hdb_res_clusters = hdb_res$cluster[hdb_res_inclust]
# get points in cluster
mymat_embedding = mymat$layout[hdb_res_inclust,]
hdb_sil = silhouette(hdb_res_clusters,dist(mymat_embedding,method = "euclidean"))
mean_sil_score = mean(summary(hdb_sil)[[2]])
n_neighbor_stat = mymat$config$n_neighbors
min_dist_stat = mymat$config$min_dist
cluster_labels = hdb_res$cluster
num_of_clusters = length(hdb_res$cluster_scores)
noise_points = sum(hdb_res$cluster== 0)
clustering_params = c(silhouette_score=mean_sil_score,umap_n_neighbors=n_neighbor_stat,umap_min_dist=min_dist_stat,hdbscan_min_cluster_size=minclust,number_of_clusters=num_of_clusters,noise_points=noise_points)
output_info = list(umap_embedding=mymat$layout,cluster_labels=cluster_labels,cluster_stats=clustering_params)
return(output_info)
}



#myTab_50pcs = read.table("~/Dropbox (HMS)/Kostic_Lab/datasets/orfletonV2/complete_linkage_analysis/clustering/multi_map_30_collapsed_processed_50PCs.txt",sep="\t",header=F)
#myTab_10pcs = read.table("~/Dropbox (HMS)/Kostic_Lab/datasets/orfletonV2/complete_linkage_analysis/clustering/multi_map_30_collapsed_processed_10PCs.txt",sep="\t",header=F)
#myTab_100pcs = read.table("~/Dropbox (HMS)/Kostic_Lab/datasets/orfletonV2/complete_linkage_analysis/clustering/multi_map_30_collapsed_processed_100PCs.txt",sep="\t",header=F)

myTab_50pcs = read.table("multi_map_30_collapsed_processed_v2_50PCs_v2_min_prevalence0.txt",sep="\t",header=F)
myTab_10pcs = read.table("multi_map_30_collapsed_processed_v2_10PCs_v2_min_prevalence0.txt",sep="\t",header=F)
myTab_100pcs = read.table("multi_map_30_collapsed_processed_v2_100PCs_v2_min_prevalence0.txt",sep="\t",header=F)


# get sample names
sample_names_50pcs = myTab_50pcs[,1]
sample_names_10pcs = myTab_10pcs[,1]
sample_names_100pcs = myTab_100pcs[,1]

# remove sample name column from matrix
myTab_50pcs = myTab_50pcs[,-1]
myTab_10pcs = myTab_10pcs[,-1]
myTab_100pcs = myTab_100pcs[,-1]

### scale SVD before continuing
# z-score normalize each PC in matrix
myTab_50pcs_col_normalized = scale(myTab_50pcs, center = TRUE, scale = TRUE)
myTab_50pcs_col_normalized = as.data.frame(myTab_50pcs_col_normalized)

myTab_10pcs_col_normalized = scale(myTab_10pcs, center = TRUE, scale = TRUE)
myTab_10pcs_col_normalized = as.data.frame(myTab_10pcs_col_normalized)

myTab_100pcs_col_normalized = scale(myTab_100pcs, center = TRUE, scale = TRUE)
myTab_100pcs_col_normalized = as.data.frame(myTab_100pcs_col_normalized)

two_components_vec = c(2)
mindist_vec = c(0.1,0.25,0.5)
nneighbors_vec = c(10,15,20,30)
all_parameter_combos_2components = expand.grid(nneighbors_vec,mindist_vec,two_components_vec)
colnames(all_parameter_combos_2components) = c("nneighbors","mindist","ncomponents")


umap_50PCs_res = apply(all_parameter_combos_2components, 1, function(myparams) umap(myTab_50pcs_col_normalized,n_neighbors=myparams[1],min_dist=myparams[2],n_components=myparams[3],random_state=42))

umap_10PCs_res = apply(all_parameter_combos_2components, 1, function(myparams) umap(myTab_10pcs_col_normalized,n_neighbors=myparams[1],min_dist=myparams[2],n_components=myparams[3],random_state=42))

umap_100PCs_res = apply(all_parameter_combos_2components, 1, function(myparams) umap(myTab_100pcs_col_normalized,n_neighbors=myparams[1],min_dist=myparams[2],n_components=myparams[3],random_state=42))

minclust_size = c(25,50,75,100)

umap_50PCs_res_hdbscan = lapply(minclust_size,function(clust_size) lapply(umap_50PCs_res, function(umap_res_temp) clac_silhouette_score(umap_res_temp,minclust=clust_size)))

umap_10PCs_res_hdbscan = lapply(minclust_size,function(clust_size) lapply(umap_10PCs_res, function(umap_res_temp) clac_silhouette_score(umap_res_temp,minclust=clust_size)))

umap_100PCs_res_hdbscan = lapply(minclust_size,function(clust_size) lapply(umap_100PCs_res, function(umap_res_temp) clac_silhouette_score(umap_res_temp,minclust=clust_size)))


#saveRDS(umap_50PCs_res_hdbscan,file = "saved_files/umap_50PCs_res_hdbscan.rds")
#saveRDS(umap_10PCs_res_hdbscan,file = "saved_files/umap_10PCs_res_hdbscan.rds")
#saveRDS(umap_100PCs_res_hdbscan,file = "saved_files/umap_100PCs_res_hdbscan.rds")
saveRDS(umap_50PCs_res_hdbscan,file = "saved_files/umap_50PCs_res_hdbscan_v2.rds")
saveRDS(umap_10PCs_res_hdbscan,file = "saved_files/umap_10PCs_res_hdbscan_v2.rds")
saveRDS(umap_100PCs_res_hdbscan,file = "saved_files/umap_100PCs_res_hdbscan_v2.rds")

```

#Now visualize UMAPs

```{r}
# function to visualize UMAPs
visualize_umap_clusters = function(umap_embeddings,clusterLabels,stats) {
  
  umap_embeddings = as.data.frame(umap_embeddings)
  mydf = cbind(umap_embeddings[,c(1,2)],as.factor(clusterLabels))
  mydf = as.data.frame(mydf)
  colnames(mydf) = c("x","y","cluster")
  mydf$shape = rep("circle",nrow(mydf))
  mydf$shape[(is.na(mydf$cluster))] = "NA"
  mydf$shape = as.factor(mydf$shape)

  title_temp = paste("silhouette score:",round(stats[1],digits=3),"\nunclustered points: ",stats[6],sep="")
  myplot = ggplot(mydf, aes(x=x, y=y,color=cluster)) + geom_point(aes(shape=shape),size=.4,alpha=.9) + scale_shape_manual(values=c(16,1)) + scale_alpha_manual(values=c(0.5,0.1)) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),panel.background = element_rect(fill="black"), axis.line = element_line(colour = "black")) +xlab("") + ylab("") + ggtitle(title_temp)
    return(myplot)
}


#umap_50PCs_res_hdbscan = readRDS("saved_files/umap_50PCs_res_hdbscan.rds")
#umap_10PCs_res_hdbscan = readRDS("saved_files/umap_10PCs_res_hdbscan.rds")
#umap_100PCs_res_hdbscan = readRDS("saved_files/umap_100PCs_res_hdbscan.rds")

umap_50PCs_res_hdbscan = readRDS("saved_files/umap_50PCs_res_hdbscan_v2.rds")
umap_10PCs_res_hdbscan = readRDS("saved_files/umap_10PCs_res_hdbscan_v2.rds")
umap_100PCs_res_hdbscan = readRDS("saved_files/umap_100PCs_res_hdbscan_v2.rds")

# get all the stats for all combinations of 50PCs
umap_50PCs_res_hdbscan_stats =lapply(umap_50PCs_res_hdbscan, function(x) lapply(x, function(y) y[3]))
umap_50PCs_res_hdbscan_stats = as.data.frame(umap_50PCs_res_hdbscan_stats)
umap_50PCs_res_hdbscan_stats = cbind(stats=rownames(umap_50PCs_res_hdbscan_stats),umap_50PCs_res_hdbscan_stats)
write.table(umap_50PCs_res_hdbscan_stats,file="umaps_multi_params/umap_50PCs_hdbscan_stats_v2.txt",sep="\t",quote=F,col.names=T,row.names=F)
## get ggplots
ggplots_50PCs = lapply(umap_50PCs_res_hdbscan, function(x) lapply(x, function(y) visualize_umap_clusters(y[[1]],y[[2]],y[[3]])))

minclust_list_50PC = lapply(umap_50PCs_res_hdbscan, function(y) sapply(y, function(x) x[[3]][[4]]))
nneighbors_list_50PC = lapply(umap_50PCs_res_hdbscan, function(y) sapply(y, function(x) x[[3]][[2]]))
mindist_list_50PC = lapply(umap_50PCs_res_hdbscan, function(y) sapply(y, function(x) x[[3]][[3]]))

for(k in 1:length(ggplots_50PCs)) {
  ggplots_xxPCs_minclust_temp = ggplots_50PCs[[k]]
  minclust_size_temp = minclust_list_50PC[[k]]
  mindist_size_temp = mindist_list_50PC[[k]]
  nneighbors_size_temp = nneighbors_list_50PC[[k]]
  # prepare row and column labels for plots
  column_titles = rep("",length(ggplots_xxPCs_minclust_temp))
  row_titles = rep("",length(ggplots_xxPCs_minclust_temp))
  column_number=4
  first_rows= seq(1,length(ggplots_xxPCs_minclust_temp),by=column_number)
  column_titles[seq(1,column_number)] = paste("n-neighbors:",nneighbors_size_temp[seq(1,column_number)],sep="")
  row_titles[first_rows] = paste("min dist:",mindist_size_temp[first_rows],sep="")
  # make the plots have column and row labels
  ggplots_xxPCs_minclust_temp = lapply(1:length(ggplots_xxPCs_minclust_temp), function(i) {
    plot_temp = ggplots_xxPCs_minclust_temp[[i]]
    plot_temp = arrangeGrob(plot_temp,top=column_titles[i],left=row_titles[i])
    return(plot_temp)
  })
  # write plots to files
  #pdf(paste("umaps_multi_params/ggplots_50PCs_minclust_",minclust_size_temp,".pdf",sep=""),width=18,height=18)
  pdf(paste("umaps_multi_params/ggplots_50PCs_minclust_",minclust_size_temp,"_v2.pdf",sep=""),width=18,height=11)
  grid.arrange(grobs = ggplots_xxPCs_minclust_temp, ncol = 4)
  dev.off()
}

# get all the stats for all combinations of 100PCs
umap_100PCs_res_hdbscan_stats =lapply(umap_100PCs_res_hdbscan, function(x) lapply(x, function(y) y[3]))
umap_100PCs_res_hdbscan_stats = as.data.frame(umap_100PCs_res_hdbscan_stats)
umap_100PCs_res_hdbscan_stats = cbind(stats=rownames(umap_100PCs_res_hdbscan_stats),umap_100PCs_res_hdbscan_stats)
write.table(umap_100PCs_res_hdbscan_stats,file="umaps_multi_params/umap_100PCs_hdbscan_stats_v2.txt",sep="\t",quote=F,col.names=T,row.names=F)
## get ggplots
ggplots_100PCs = lapply(umap_100PCs_res_hdbscan, function(x) lapply(x, function(y) visualize_umap_clusters(y[[1]],y[[2]],y[[3]])))


minclust_list_100PC = lapply(umap_100PCs_res_hdbscan, function(y) sapply(y, function(x) x[[3]][[4]]))
nneighbors_list_100PC = lapply(umap_100PCs_res_hdbscan, function(y) sapply(y, function(x) x[[3]][[2]]))
mindist_list_100PC = lapply(umap_100PCs_res_hdbscan, function(y) sapply(y, function(x) x[[3]][[3]]))


for(k in 1:length(ggplots_100PCs)) {
  ggplots_xxPCs_minclust_temp = ggplots_100PCs[[k]]
  minclust_size_temp = minclust_list_100PC[[k]]
  mindist_size_temp = mindist_list_100PC[[k]]
  nneighbors_size_temp = nneighbors_list_100PC[[k]]

  # prepare row and column labels for plots
  column_titles = rep("",length(ggplots_xxPCs_minclust_temp))
  row_titles = rep("",length(ggplots_xxPCs_minclust_temp))
  column_number=4
  first_rows= seq(1,length(ggplots_xxPCs_minclust_temp),by=column_number)
  column_titles[seq(1,column_number)] = paste("n-neighbors:",nneighbors_size_temp[seq(1,column_number)],sep="")
  row_titles[first_rows] = paste("min dist:",mindist_size_temp[first_rows],sep="")
  # make the plots have column and row labels
  ggplots_xxPCs_minclust_temp = lapply(1:length(ggplots_xxPCs_minclust_temp), function(i) {
    plot_temp = ggplots_xxPCs_minclust_temp[[i]]
    plot_temp = arrangeGrob(plot_temp,top=column_titles[i],left=row_titles[i])
    return(plot_temp)
  })
  # write plots to files
  #pdf(paste("umaps_multi_params/ggplots_50PCs_minclust_",minclust_size_temp,".pdf",sep=""),width=18,height=18)
  pdf(paste("umaps_multi_params/ggplots_100PCs_minclust_",minclust_size_temp,"_v2.pdf",sep=""),width=18,height=18)
  grid.arrange(grobs = ggplots_xxPCs_minclust_temp, ncol = 4)
  dev.off()
}

# get all the stats for all combinations of 10PCs
umap_10PCs_res_hdbscan_stats =lapply(umap_10PCs_res_hdbscan, function(x) lapply(x, function(y) y[3]))
umap_10PCs_res_hdbscan_stats = as.data.frame(umap_10PCs_res_hdbscan_stats)
umap_10PCs_res_hdbscan_stats = cbind(stats=rownames(umap_10PCs_res_hdbscan_stats),umap_10PCs_res_hdbscan_stats)
#write.table(umap_10PCs_res_hdbscan_stats,file="umaps_multi_params/umap_10PCs_hdbscan_stats.txt",sep="\t",quote=F,col.names=T,row.names=F)
write.table(umap_10PCs_res_hdbscan_stats,file="umaps_multi_params/umap_10PCs_hdbscan_stats_v2.txt",sep="\t",quote=F,col.names=T,row.names=F)
## get ggplots
ggplots_10PCs = lapply(umap_10PCs_res_hdbscan, function(x) lapply(x, function(y) visualize_umap_clusters(y[[1]],y[[2]],y[[3]])))

# write to output files

minclust_list_10PC = lapply(umap_10PCs_res_hdbscan, function(y) sapply(y, function(x) x[[3]][[4]]))
nneighbors_list_10PC = lapply(umap_10PCs_res_hdbscan, function(y) sapply(y, function(x) x[[3]][[2]]))
mindist_list_10PC = lapply(umap_10PCs_res_hdbscan, function(y) sapply(y, function(x) x[[3]][[3]]))


for(k in 1:length(ggplots_10PCs)) {
  ggplots_xxPCs_minclust_temp = ggplots_10PCs[[k]]
  minclust_size_temp = minclust_list_10PC[[k]]
  mindist_size_temp = mindist_list_10PC[[k]]
  nneighbors_size_temp = nneighbors_list_10PC[[k]]

  # prepare row and column labels for plots
  column_titles = rep("",length(ggplots_xxPCs_minclust_temp))
  row_titles = rep("",length(ggplots_xxPCs_minclust_temp))
  column_number=4
  first_rows= seq(1,length(ggplots_xxPCs_minclust_temp),by=column_number)
  column_titles[seq(1,column_number)] = paste("n-neighbors:",nneighbors_size_temp[seq(1,column_number)],sep="")
  row_titles[first_rows] = paste("min dist:",mindist_size_temp[first_rows],sep="")
  # make the plots have column and row labels
  ggplots_xxPCs_minclust_temp = lapply(1:length(ggplots_xxPCs_minclust_temp), function(i) {
    plot_temp = ggplots_xxPCs_minclust_temp[[i]]
    plot_temp = arrangeGrob(plot_temp,top=column_titles[i],left=row_titles[i])
    return(plot_temp)
  })
  # write plots to files
  #pdf(paste("umaps_multi_params/ggplots_50PCs_minclust_",minclust_size_temp,".pdf",sep=""),width=18,height=18)
  pdf(paste("umaps_multi_params/ggplots_10PCs_minclust_",minclust_size_temp,"_v2.pdf",sep=""),width=18,height=18)
  grid.arrange(grobs = ggplots_xxPCs_minclust_temp, ncol = 4)
  dev.off()
}

```

##Okay now I want to do subclustering analysis on clusters 7, 2, 3, and 4

```{r}
build_UMAPS = function(working_dir,cluster_num) {
  setwd(working_dir)
  myTab_50pcs = read.table(paste("multi_map_30_collapsed_processed_cluster",cluster_num,"samples_50PCs_v2_min_prevalence0.txt",sep=""),sep="\t",header=F)
  myTab_10pcs = read.table(paste("multi_map_30_collapsed_processed_cluster",cluster_num,"samples_10PCs_v2_min_prevalence0.txt",sep=""),sep="\t",header=F)
  myTab_100pcs = read.table(paste("multi_map_30_collapsed_processed_cluster",cluster_num,"samples_100PCs_v2_min_prevalence0.txt",sep=""),sep="\t",header=F)

  # get sample names
  sample_names_50pcs = myTab_50pcs[,1]
  sample_names_10pcs = myTab_10pcs[,1]
  sample_names_100pcs = myTab_100pcs[,1]

  # remove sample name column from matrix
  myTab_50pcs = myTab_50pcs[,-1]
  myTab_10pcs = myTab_10pcs[,-1]
  myTab_100pcs = myTab_100pcs[,-1]

  ### scale SVD before continuing
  # z-score normalize each PC in matrix
  myTab_50pcs_col_normalized = scale(myTab_50pcs, center = TRUE, scale = TRUE)
  myTab_50pcs_col_normalized = as.data.frame(myTab_50pcs_col_normalized)

  myTab_10pcs_col_normalized = scale(myTab_10pcs, center = TRUE, scale = TRUE)
  myTab_10pcs_col_normalized = as.data.frame(myTab_10pcs_col_normalized)

  myTab_100pcs_col_normalized = scale(myTab_100pcs, center = TRUE, scale = TRUE)
  myTab_100pcs_col_normalized = as.data.frame(myTab_100pcs_col_normalized)

  # run UMAP
  two_components_vec = c(2)
  mindist_vec = c(0.1,0.25,0.5)
  nneighbors_vec = c(10,15,20,30)
  all_parameter_combos_2components = expand.grid(nneighbors_vec,mindist_vec,two_components_vec)
  colnames(all_parameter_combos_2components) = c("nneighbors","mindist","ncomponents")


  umap_50PCs_res = apply(all_parameter_combos_2components, 1, function(myparams) umap(myTab_50pcs_col_normalized,n_neighbors=myparams[1],min_dist=myparams[2],n_components=myparams[3],random_state=42))

  umap_10PCs_res = apply(all_parameter_combos_2components, 1, function(myparams) umap(myTab_10pcs_col_normalized,n_neighbors=myparams[1],min_dist=myparams[2],n_components=myparams[3],random_state=42))

  umap_100PCs_res = apply(all_parameter_combos_2components, 1, function(myparams) umap(myTab_100pcs_col_normalized,n_neighbors=myparams[1],min_dist=myparams[2],n_components=myparams[3],random_state=42))

  saveRDS(umap_50PCs_res,file = paste("saved_files/umap_50PCs_res_recluster",cluster_num,"_v2.rds",sep=""))
  saveRDS(umap_10PCs_res,file = paste("saved_files/umap_10PCs_res_recluster",cluster_num,"_v2.rds",sep=""))
  saveRDS(umap_100PCs_res,file = paste("saved_files/umap_100PCs_res_recluster",cluster_num,"_v2.rds",sep=""))
}

build_UMAPS(working_dir="~/Dropbox (HMS)/Kostic_Lab/datasets/orfletonV2/complete_linkage_analysis/clustering/cluster7_recluster/",cluster_num=7)
build_UMAPS(working_dir="~/Dropbox (HMS)/Kostic_Lab/datasets/orfletonV2/complete_linkage_analysis/clustering/cluster3_recluster/",cluster_num=3)
build_UMAPS(working_dir="~/Dropbox (HMS)/Kostic_Lab/datasets/orfletonV2/complete_linkage_analysis/clustering/cluster2_recluster/",cluster_num=2)
build_UMAPS(working_dir="~/Dropbox (HMS)/Kostic_Lab/datasets/orfletonV2/complete_linkage_analysis/clustering/cluster4_recluster/",cluster_num=4)

```

##Next plot UMAPS



```{r}
library(ggplot2)
library(gridExtra)
visualize_umap_clusters = function(umap_embeddings,clusterLabels) {
  
  umap_embeddings = as.data.frame(umap_embeddings)
  mydf = cbind(umap_embeddings[,c(1,2)],as.factor(clusterLabels))
  mydf = as.data.frame(mydf)
  colnames(mydf) = c("x","y","cluster")
  mydf$shape = rep("circle",nrow(mydf))
  mydf$shape[(is.na(mydf$cluster))] = "NA"
  mydf$shape = as.factor(mydf$shape)

  myplot = ggplot(mydf, aes(x=x, y=y,color=cluster)) + geom_point(aes(shape=shape),size=.4,alpha=.9) + scale_shape_manual(values=c(16,1)) + scale_alpha_manual(values=c(0.5,0.1)) + theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),panel.background = element_rect(fill="black"), axis.line = element_line(colour = "black")) +xlab("") + ylab("")
    return(myplot)
}


visualize_UMAPs = function(working_dir,cluster_num) {
  setwd(working_dir)
  myTab_50pcs = read.table(paste("multi_map_30_collapsed_processed_cluster",cluster_num,"samples_50PCs_v2_min_prevalence0.txt",sep=""),sep="\t",header=F)
  myTab_10pcs = read.table(paste("multi_map_30_collapsed_processed_cluster",cluster_num,"samples_10PCs_v2_min_prevalence0.txt",sep=""),sep="\t",header=F)
  myTab_100pcs = read.table(paste("multi_map_30_collapsed_processed_cluster",cluster_num,"samples_100PCs_v2_min_prevalence0.txt",sep=""),sep="\t",header=F)


  # get sample names
  sample_names_50pcs = myTab_50pcs[,1]
  sample_names_10pcs = myTab_10pcs[,1]
  sample_names_100pcs = myTab_100pcs[,1]

  metadata = read.csv("~/Dropbox (HMS)/Kostic_Lab/datasets/orfletonV2/human_env_metadata_march_22_2021.csv")

  metadata_50pc_order = metadata[match(sample_names_50pcs,metadata$prokka_id),]
  metadata_10pc_order = metadata[match(sample_names_10pcs,metadata$prokka_id),]
  metadata_100pc_order = metadata[match(sample_names_100pcs,metadata$prokka_id),]


  two_components_vec = c(2)
  mindist_vec = c(0.1,0.25,0.5)
  nneighbors_vec = c(10,15,20,30)
  all_parameter_combos_2components = expand.grid(nneighbors_vec,mindist_vec,two_components_vec)
  colnames(all_parameter_combos_2components) = c("nneighbors","mindist","ncomponents")

  nneighbors = all_parameter_combos_2components$nneighbors
  mindist = all_parameter_combos_2components$mindist
  column_number=4

  column_titles = rep("",nrow(all_parameter_combos_2components))
  row_titles = rep("",nrow(all_parameter_combos_2components))
  first_rows= seq(1,nrow(all_parameter_combos_2components),by=column_number)
  column_titles[seq(1,column_number)] = paste("n-neighbors:",nneighbors[seq(1,column_number)],sep="")
  row_titles[first_rows] = paste("min dist:",mindist[first_rows],sep="")


  umap_50PCs_res_hdbscan = readRDS(paste("saved_files/umap_50PCs_res_recluster",cluster_num,"_v2.rds",sep=""))
  umap_10PCs_res_hdbscan = readRDS(paste("saved_files/umap_10PCs_res_recluster",cluster_num,"_v2.rds",sep=""))
  umap_100PCs_res_hdbscan = readRDS(paste("saved_files/umap_100PCs_res_recluster",cluster_num,"_v2.rds",sep=""))

  umap_list = list(fiftyPC=umap_50PCs_res_hdbscan,tenPC=umap_10PCs_res_hdbscan,onehundredPC=umap_100PCs_res_hdbscan)
  my_metadata_list = list(metadata_50pc_order,metadata_10pc_order,metadata_100pc_order)
  metadata_col_names = c("ecology","health_status","age","westernized")

  plot_UMAPs = function(umap_temp, umap_name, my_metadata,metadata_col_name,cluster_num) {
    ggplot_XXPCs = lapply(umap_temp, function(x) visualize_umap_clusters(x$layout,my_metadata[,metadata_col_name]))
    ggplots_XXPCs_2 = sapply(1:length(ggplot_XXPCs), function(i) {
      plot_temp = ggplot_XXPCs[[i]]
      plot_temp = arrangeGrob(plot_temp,top=column_titles[i],left=row_titles[i])
      return(plot_temp)
    })
    pdf(paste("umaps_multi_params/ggplots_cluster",cluster_num,"_",umap_name,"_",metadata_col_name,"_minclust_v2.pdf",sep=""),width=18,height=18)
    grid.arrange(grobs = ggplots_XXPCs_2, ncol = 4)
    dev.off()
  }
  lapply(seq(1,length(umap_list)), function(mynum) {
    umap_temp = umap_list[[mynum]]
    umap_name = names(umap_list)[mynum]
    my_metadata = my_metadata_list[[mynum]]
    sapply(metadata_col_names, function(meta_col) plot_UMAPs(umap_temp = umap_temp,umap_name = umap_name, my_metadata =my_metadata, metadata_col_name = meta_col,cluster_num = cluster_num))
  })
}

visualize_UMAPs(working_dir="~/Dropbox (HMS)/Kostic_Lab/datasets/orfletonV2/complete_linkage_analysis/clustering/cluster7_recluster/",cluster_num=7)
visualize_UMAPs(working_dir="~/Dropbox (HMS)/Kostic_Lab/datasets/orfletonV2/complete_linkage_analysis/clustering/cluster3_recluster/",cluster_num=3)
visualize_UMAPs(working_dir="~/Dropbox (HMS)/Kostic_Lab/datasets/orfletonV2/complete_linkage_analysis/clustering/cluster2_recluster/",cluster_num=2)
visualize_UMAPs(working_dir="~/Dropbox (HMS)/Kostic_Lab/datasets/orfletonV2/complete_linkage_analysis/clustering/cluster4_recluster/",cluster_num=4)

```

##Okay. so it looks like for 100 PCs is best for cluster 7 I think. lets do n neighbors 15, dist 0.1 which is default params

### OK so its looking like for cluster 3, 50PCs probably best

##Cluster 4. I think 50 PCs are best. Although 100PCs may give better separation for ecologies
